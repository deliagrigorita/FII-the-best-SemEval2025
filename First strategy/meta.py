# Importing the required libraries
import json
import os
import re
from typing import Dict, List, Set

# Whether to use the verbose mode.
VERBOSE = False

# List of entity types to be evaluated.
# Used to filter the evaluation to a specific entity type.
ENTITY_TYPES = [
    "Musical work",
    "Artwork",
    "Food",
    "Animal",
    "Plant",
    "Book",
    "Book series",
    "Fictional entity",
    "Landmark",
    "Movie",
    "Place of worship",
    "Natural place",
    "TV series",
    "Person",
]

PATH_TO_DATA_DIR = "data"

# Change the split to "validation" or "test" to evaluate the predictions on the respective split.
SPLIT = "validation"

# Change the target language to evaluate the predictions on the respective language.
TARGET_LANGUAGE = "es_ES"

# Change the system name to evaluate the predictions generated by the respective system.
SYSTEM_NAME = "model_name"

# Load the references file.
PATH_TO_REFERENCES = os.path.join(
    PATH_TO_DATA_DIR,
    "references",
    SPLIT,
    f"{TARGET_LANGUAGE}.jsonl",
)

# Path to the predictions file.
PATH_TO_PREDICTIONS = os.path.join(
    PATH_TO_DATA_DIR,
    "predictions",
    SYSTEM_NAME,
    SPLIT,
    f"{TARGET_LANGUAGE}.jsonl",
)

def load_references(input_path: str, entity_types: List[str]) -> List[dict]:
    """
    Load data from the input file (JSONL) and return a list of dictionaries, one for each instance in the dataset.

    Args:
        input_path (str): Path to the input file.
        entity_types (List[str]): List of entity types to filter the evaluation.

    Returns:
        List[dict]: List of dictionaries, one for each instance in the dataset.
    """
    data = []

    with open(input_path, encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue

            line_data = json.loads(line)

            # Skip instances with empty target list and log a warning.
            if not line_data["targets"]:
                print(f"Empty target list for instance {line_data['id']}")
                continue

            # Filter the evaluation to the specified entity types if provided.
            if entity_types and not any(
                e in line_data["entity_types"] for e in entity_types
            ):
                continue

            data.append(line_data)

    return data

def load_predictions(input_path: str) -> Dict[str, str]:
    """
    Load data from the input file (JSONL) and return a dictionary with the instance ID as key and the prediction as value.

    Args:
        input_path (str): Path to the input file.

    Returns:
        Dict[str, str]: Dictionary with the instance ID as key and the prediction as value.
    """
    data = {}

    with open(input_path, encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue

            line_data = json.loads(line)
            prediction = line_data["prediction"]

            # Get the instance ID from a substring of the ID.
            pattern = re.compile(r"Q[0-9]+_[0-9]")
            match = pattern.match(line_data["id"])
            if not match:
                raise ValueError(f"Invalid instance ID: {line_data['id']}")

            instance_id = match.group(0)
            data[instance_id] = prediction

    return data

def compute_entity_name_translation_accuracy(
    predictions: Dict[str, str],
    mentions: Dict[str, Set[str]],
    verbose: bool = False,
) -> dict:
    """
    Compute the entity name translation accuracy.

    Args:
        predictions (Dict[str, str]): Predictions of the model.
        mentions (Dict[str, Set[str]]): Ground truth entity mentions.
        verbose (bool): Set to True to print every wrong match.

    Returns:
        dict: Dictionary with the following
            - correct: Number of correct matches.
            - total: Total number of instances.
            - accuracy: Accuracy of the model.
    """
    correct, total = 0, 0

    for instance_id, instance_mentions in mentions.items():
        # Check that there is at least one entity mention for the instance.
        assert instance_mentions, f"No mentions for instance {instance_id}"

        # Increment the total count of instances (for recall calculation).
        total += 1

        # Check that there is a prediction for the instance.
        if instance_id not in predictions:
            if verbose:
                print(
                    f"No prediction for instance {instance_id}. Check that this is expected behavior, as it may affect the evaluation."
                )
            continue

        prediction = predictions[instance_id]
        normalized_translation = prediction.casefold()
        entity_match = False

        for mention in instance_mentions:
            normalized_mention = mention.casefold()

            # Check if the normalized mention is a substring of the normalized translation.
            # If it is, consider the prediction (the entity name translation) correct.
            if normalized_mention in normalized_translation:
                correct += 1
                entity_match = True
                break

        # Log the prediction and the ground truth mentions for every wrong match if verbose is set.
        if not entity_match and verbose:
            print(f"Prediction: {prediction}")
            print(f"Ground truth mentions: {instance_mentions}")
            print("")

    return {
        "correct": correct,
        "total": total,
        "accuracy": correct / total if total > 0 else 0.0,
    }

def get_mentions_from_references(data: List[dict]) -> Dict[str, Set[str]]:
    """
    Load the ground truth entity mentions from the data.

    Args:
        data (List[dict]): List of dictionaries, one for each instance in the dataset.

    Returns:
        Dict[str, Set[str]]: Dictionary with the instance ID as key and the set of entity mentions as value.
    """
    mentions = {}

    for instance in data:
        instance_id = instance["id"]
        instance_mentions = set()

        for target in instance["targets"]:
            mention = target["mention"]
            instance_mentions.add(mention)

        mentions[instance_id] = instance_mentions

    return mentions

print(f"Loading data from {PATH_TO_REFERENCES}...")
reference_data = load_references(PATH_TO_REFERENCES, ENTITY_TYPES)
mentions = get_mentions_from_references(reference_data)
assert len(mentions) == len(reference_data)
print(f"Loaded {len(reference_data)} instances.")

print(f"Loading data from {PATH_TO_PREDICTIONS}...")
prediction_data = load_predictions(PATH_TO_PREDICTIONS)
print(f"Loaded {len(prediction_data)} predictions.")

print("Computing entity name translation accuracy...")
entity_name_translation_accuracy = compute_entity_name_translation_accuracy(
    prediction_data,
    mentions,
    verbose=VERBOSE,
)

print("=============================================")
print(f"Evaluation results in {TARGET_LANGUAGE}")
print(f"Correct instances   = {entity_name_translation_accuracy['correct']}")
print(f"Total instances     = {entity_name_translation_accuracy['total']}")

accuracy = entity_name_translation_accuracy["accuracy"] * 100.0
print("-----------------------------")
print(f"m-ETA               = {accuracy:.2f}")
print("=============================================")
print("")

print("Evaluation completed.")